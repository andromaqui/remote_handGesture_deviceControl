{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "# import the necessary packages\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseModel = ResNet50(weights=\"imagenet\", include_top=False,input_tensor=Input(shape=(128, 128, 3)))\n",
    "\n",
    "# construct the head of the model that will be placed on top of the\n",
    "# the base model\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(4, 4))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(256, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(4, activation=\"softmax\")(headModel)\n",
    "\n",
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "# loop over all layers in the base model and freeze them so they will\n",
    "# *not* be updated during the training process\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lettersDict = {'A' :0, 'B':1, 'U':2, 'V':3} \n",
    "pathToImages = []\n",
    "\n",
    "##############################\n",
    "# here we collect all the paths\n",
    "# to our train / test images\n",
    "pathToImages = []\n",
    "for root, dirs, files in os.walk(\".\", topdown=False): \n",
    "    for name in files:\n",
    "        path = os.path.join(root, name)\n",
    "        if path.endswith(\"jpg\"):\n",
    "            pathToImages.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] # Image data\n",
    "y = [] # Labels\n",
    "\n",
    "# Loops through imagepaths to load images and labels into arrays\n",
    "for path in pathToImages:\n",
    "    # Reads image and returns np.array\n",
    "    img = cv2.imread(path) \n",
    "    img = cv2.resize(img, (128, 128)) \n",
    "\n",
    "    X.append(img)\n",
    "    try:\n",
    "        label = path.split(\"/\")[3].split(\".\")[0][0]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(path)\n",
    "    letterToNumber = lettersDict.get(label)\n",
    "    y.append(letterToNumber)\n",
    "\n",
    "\n",
    "X = np.array(X, dtype=\"uint8\")\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(667, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "ts = 0.3 # Percentage of images that we want to use for testing. The rest is used for training.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ts, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "8/8 - 9s - loss: 2.1690 - accuracy: 0.2983 - val_loss: 1.0779 - val_accuracy: 0.4677\n",
      "Epoch 2/15\n",
      "8/8 - 8s - loss: 1.5745 - accuracy: 0.4313 - val_loss: 0.7772 - val_accuracy: 0.6915\n",
      "Epoch 3/15\n",
      "8/8 - 8s - loss: 1.1030 - accuracy: 0.5408 - val_loss: 0.6167 - val_accuracy: 0.7761\n",
      "Epoch 4/15\n",
      "8/8 - 8s - loss: 0.9209 - accuracy: 0.6524 - val_loss: 0.4786 - val_accuracy: 0.8507\n",
      "Epoch 5/15\n",
      "8/8 - 8s - loss: 0.7034 - accuracy: 0.7039 - val_loss: 0.4058 - val_accuracy: 0.8806\n",
      "Epoch 6/15\n",
      "8/8 - 8s - loss: 0.5598 - accuracy: 0.7918 - val_loss: 0.3517 - val_accuracy: 0.9005\n",
      "Epoch 7/15\n",
      "8/8 - 8s - loss: 0.4496 - accuracy: 0.8219 - val_loss: 0.3051 - val_accuracy: 0.9254\n",
      "Epoch 8/15\n",
      "8/8 - 8s - loss: 0.4723 - accuracy: 0.8197 - val_loss: 0.2636 - val_accuracy: 0.9353\n",
      "Epoch 9/15\n",
      "8/8 - 8s - loss: 0.4197 - accuracy: 0.8305 - val_loss: 0.2404 - val_accuracy: 0.9502\n",
      "Epoch 10/15\n",
      "8/8 - 8s - loss: 0.3329 - accuracy: 0.8691 - val_loss: 0.2222 - val_accuracy: 0.9403\n",
      "Epoch 11/15\n",
      "8/8 - 8s - loss: 0.2504 - accuracy: 0.9185 - val_loss: 0.2074 - val_accuracy: 0.9502\n",
      "Epoch 12/15\n",
      "8/8 - 8s - loss: 0.2376 - accuracy: 0.9185 - val_loss: 0.1910 - val_accuracy: 0.9602\n",
      "Epoch 13/15\n",
      "8/8 - 9s - loss: 0.2426 - accuracy: 0.9335 - val_loss: 0.1819 - val_accuracy: 0.9602\n",
      "Epoch 14/15\n",
      "8/8 - 8s - loss: 0.1923 - accuracy: 0.9464 - val_loss: 0.1751 - val_accuracy: 0.9602\n",
      "Epoch 15/15\n",
      "8/8 - 9s - loss: 0.1934 - accuracy: 0.9464 - val_loss: 0.1674 - val_accuracy: 0.9652\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "opt = Adam(lr=1e-4, decay=1e-4 / 30)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
    "\n",
    "# Trains the model for a given number of epochs (iterations on a dataset) and validates it.\n",
    "model.fit(X_train, y_train, epochs=15, batch_size=64, verbose=2, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save entire model to a HDF5 file\n",
    "model.save('model8.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201, 128, 128, 3)\n",
      "7/7 [==============================] - 2s 340ms/step - loss: 0.1674 - accuracy: 0.9652\n",
      "Test accuracy: 96.52%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy: {:2.2f}%'.format(test_acc*100))\n",
    "predictions = model.predict(X_test) # Make predictions towards the test set\n",
    "np.argmax(predictions[0]), y_test[0] # If same, got it right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
